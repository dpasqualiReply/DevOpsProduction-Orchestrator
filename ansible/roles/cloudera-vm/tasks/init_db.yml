---
# tasks file for init_db.yml

- name: Setup DBFeeder and movielens dataset
  include_role:
    name: movielens-init

- name: Read generated cloudera-scm password
  shell: head -1 /var/lib/cloudera-scm-server-db/data/generated_password.txt
  register: password

#- debug:
#    msg: "{{ password['stdout'] }}"

- name: locally store password to configure JDBC connector
  local_action:
    module: copy
    content: "{{ password['stdout'] }}"
    dest: /opt/ansible/cloudera_psql_passwd.txt
    force: yes
    group: root
    owner: root
    mode: 0555

- name: Schedule DBFeeder daily
  cron:
    name: "Ingest movielens"
    user: root
    special_time: daily
    job: python $DBFEEDER_HOME/DBFeeder.py --fraction=0.001 --datasets=$M20_PATH --psql_user=cloudera-scm --psql_password="{{ password['stdout'] }}"
  register: first_run

- name: initialize database
  command: sudo -i python $DBFEEDER_HOME/DBFeeder.py --init --datasets=$M20_PATH --psql_user=cloudera-scm --psql_password="{{ password['stdout'] }}"
  when: first_run.changed

- name: export HADOOP_USER_NAME
  lineinfile:
    path: /etc/profile.d/exports.sh
    state: present
    insertafter: EOF
    line: 'export HADOOP_USER_NAME=hdfs'

- name: Download postgresql driver
  get_url:
    url: http://jdbc.postgresql.org/download/postgresql-9.2-1002.jdbc4.jar
    dest: /opt/postgresql-9.2-1002.jdbc4.jar
    mode: 0440

- name: Copy Postgresql driver to sqoop var directory
  copy:
   src: /opt/postgresql-9.2-1002.jdbc4.jar
   dest: /var/lib/sqoop/postgresql-9.2-1002.jdbc4.jar
   remote_src: yes

- name: Schedule genome tags ingestion with sqoop
  cron:
    name: "Ingest Genome Tags"
    user: root
    special_time: daily
    job:  sudo sqoop import --connect 'jdbc:postgresql://localhost:7432/postgres' --username 'cloudera-scm' --password '"{{ password['stdout'] }}' --table 'genometags' --hive-table 'datalake.genometags' --hive-import  --check-column id --append --incremental 'append'
  when: first_run.changed

- name: Schedule movies ingestion with sqoop
  cron: 
    name: "Ingest Movies"
    user: root
    special_time: daily
    job:  sudo sqoop import --connect 'jdbc:postgresql://localhost:7432/postgres' --username 'cloudera-scm' --password '"{{ password['stdout'] }}' --table 'movies' --hive-table 'datalake.movies' --hive-import  --check-column id --append --incremental 'append'
  when: first_run.changed 

- name: Schedule links ingestion with sqoop
  cron: 
    name: "Ingest Links"
    user: root
    special_time: daily
    job: sudo sqoop import --connect 'jdbc:postgresql://localhost:7432/postgres' --username 'cloudera-scm' --password '"{{ password['stdout'] }}' --table 'links' --hive-table 'datalake.links' --hive-import  --check-column id --append --incremental 'append'
  when: first_run.changed  
